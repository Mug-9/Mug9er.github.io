---
title: 吴恩达机器学习1
mathjax: true
categories: [机器学习, 学习笔记]
tags: [机器学习, 学习笔记]
abbrlink: 79200c28
date: 2021-05-30 12:12:23
img: https://cdn.jsdelivr.net/gh/Mug-9/imge-stroage@master/Andrew-ML/wallhaven-72jmve.42eeeqocjso0.jpg
---

吴恩达机器学习笔记(一)

<!-- less -->

## 什么是机器学习

>$A\ computer\ program\ is\ said\ to\ learn\ from\  experience\ E\ with\ respect\ to\ some\ class\ of\ tasks\ T\ and\ performance\ measure\ P\ ,$
>
>$\ if\ its\ performance\ at\ tasks\ in\ T,\ as\ measured\ by\ P,\ improves\ with\ experience\ E.$ 

一个计算机程序可以从经验$E$中学习，执行任务$T$，由$P$做性能评估，并且他在$T$任务中的表现(由$P$衡量)随着经验$E$的提高而提高。

以下跳棋为例:

>$E:$  下过很多跳棋的经验
>
>$T：$下跳棋的任务
>
>$P ：$下一局赢下跳棋的可能性

一般的任何机器学习都可以分类两类：监督学习和非监督学习

### 什么是监督学习

>$In\ supervised\ learning,\ we\ are\ given\ a data\ set\ and\ already\ know\ what\ our\ correct\ output\ should\ look\ like,$
>
>$having\ the\ idea\ that\ there\ is\ a\ relationship\ between\ the\ input\ and\ the\ output.$

在监督学习中，我们已知一个数据集，并且已经知道正确的输出应该是什么样的，我们知道输入与输出之间存在着一种关系。

在监督学习中，我们已经知道数据集的含义、分布，根据已知的信息来预测。

>$Supervised\ learning\ problems\ are\ categorized\ into\ "regression"\ and\ "classification"\ problems.\ $
>
>$In\ a\ regression\ problem,\ we\ are\ trying\ to\ predict\ results\ within\ a\ continuous\ output,\ meaning\ that \ $
>
>$we\ are\ trying\ to\ map\ input\ variables\ to\ some\ continuous\ function.\ In\ a\ classification\ problem,\ we\ $
>
>$ are\  instead\ trying\ to\ predict\ results\ in\ a\ discrete\ output.\ In\ other\ words,\ we\ are\ trying\ to\ map\ input\ $
>
>$variables\ into\ discrete\ categories.\ $

监督学习问题分为“回归”问题和“分类”问题。在回归问题中，我们试图预测连续输出中的结果，这意味着我们试图将输入变量映射到某个连续函数。在分类问题中，我们试图预测离散输出中的结果。换句话说，我们试图将输入变量映射到离散的类别中。

#### 例子

回归问题：给一张照片，去预测照片中人的年龄

分类问题：对于患有肿瘤的病人，去预测肿瘤是良性还是恶性

### 什么是无监督学习

>$Unsupervised\ learning\ allows\ us\ to\ approach\ problems\ with\ little\ or\ no\ idea\ what\ our\ results\ should\  $
>
>$look\ like.\ We\ can\ derive\ structure\ from\ data\ where\ we\ don't\ necessarily\ know\ the\ effect\ of\ the\ variables.\ $
>
>$We\ can\ derive\ this\ structure\ by\ clustering\ the\ data\ based\ on\ relationships\ among\ the\ variables\ in\ the\ data.$
>
>$With\ unsupervised\ learning\ there\ is\ no\ feedback\ based\ on\ the\ prediction\ results.$

无监督学习让我们在几乎不知道结果是什么的情况下处理问题。我们可以从数据中得出结构，而我们并不一定知道变量的影响。

我们可以根据数据中变量之间的关系对数据进行聚类，从而得到这种结构。

在无监督学习中，没有基于预测结果的反馈。

#### 例子

收集100万个不同的基因，然后找到一种方法将这些基因分组，这些分组在某种程度上是相似的，或者由不同的变量(如寿命、位置、角色等)相关的。

## 建立符号规则

$m$ 表示训练集数量，对于训练集中的每一项，我们使用$x^{(i)}$表示训练集中的第$i$行输入的变量，使用$y^{(i)}$表示训练集中第$i$行输出的变量 。

一对$(x^{(i)},y^{(i)})$成为一个训练样例，$(i)$只是表示训练集中的索引，而不是次幂。还使用$X$来表示输入值的空间，$Y$表示输出值的空间。

## 监督学习

>$To\ describe\ the\ supervised\ learning\ problem\ slightly\ more\ formally,\ our\ goal\ is,\ given\ a\ training\ set,\ $
>
>$to\ learn\ a\ function\ h\ :\ X\ →\ Y\ so\ that\ h(x)\ is\ a\ “good”\ predictor\ for\ the\ corresponding\ value\ of\ y.\ $
>
>$For\ historical\ reasons,\ this\ function\ h\ is\ called\ a\ hypothesis.\ Seen\ pictorially,\ the\ process\ is\ $
>
> $therefore\ like\ this:\ $

为了更正式地描述监督学习问题，我们的目标是，给定一个训练集，学习一个函数$h: X → Y$，使$h(X)$是对应的$Y$值的一个很好的预测器。由于历史原因，这个函数$h$被称为一个假设。从图片上看，这个过程是这样的

![supervised learning process](https://cdn.jsdelivr.net/gh/Mug-9/imge-stroage@master/Andrew-ML/supervised learning process.3tlcgn2ah0o0.png)

### 代价函数

假设的$h$函数由$h_{\theta}(x)=\theta_0 + \theta_1x$拟合而来，$\theta_0$和$\theta_1$是两个未知参数

我们的目的是选择最适合的$\theta_0,\theta_1$以便于$h_{\theta}(x)$最接近与真正的训练集对应$Y$值的分布

代价函数$J(\theta_0,\theta_1)=\frac{1}{2m}\sum\limits_{i=1}^m(\hat y_i -y_i)^2=\frac{1}{2m}\sum\limits_{i=1}^m(h_{\theta}(x^{(i)})-y^{(i)})^2$表示$h$函数与$Y$值之间的误差

$Goal:\ \min\limits_{\theta_0,\theta_1}J(\theta_0, \theta_1)$

把$\theta_0$设成0,不同的$\theta_1$对应的$h$函数所形成的误差在$J(\theta_1)$的图像上呈现一个二次函数的图像，寻找$J(\theta_1)$的最小值，就是寻找最适合，最拟合与$Y$的$h(\theta_1)$函数

![Cost Function](https://cdn.jsdelivr.net/gh/Mug-9/imge-stroage@master/Andrew-ML/Cost Function.x637adlj7nk.png)