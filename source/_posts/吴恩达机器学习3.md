---
title: 吴恩达机器学习3
mathjax: true
date: 2021-06-25 21:37:42
img: https://cdn.jsdelivr.net/gh/Mug-9/imge-stroage@master/cover/wallhaven-dp3yg3.qt5rkp8gx68.jpg
categories: [机器学习, 学习笔记]
tags: [机器学习, 学习笔记]
---

吴恩达机器学习笔记(三)

<!--less-->

## 逻辑回归

### 二元分类

二元分类中$y$值只能取两个值，0或1

$y=\{ 0, 1\}$

一般的话，0代表没有，1代表有

### 逻辑回归

逻辑回归实际是一种分类算法，逻辑回归的输出值在0到1之间

$0\le h_{\theta}(x)\le1$

线性回归的一般公式是：$h_{\theta}(x)=\theta^Tx$,得到的是一个数值

而逻辑回归的公式则为：$h_{\theta}(x)=g(\theta^Tx)\\g(z)=\frac{1}{1+e^{-z}}$

$g$函数一般被称为 $sigmoid\ $函数或 $logistic\ $函数

![逻辑函数](https://cdn.jsdelivr.net/gh/Mug-9/imge-stroage@master/Andrew-ML/logisic.3eotdbigmhu0.png)

逻辑函数$h$的曲线在0到1之间，也可以说逻辑曲线的值参数$x$为1的可能性

$h_{\theta}(x)=p(y=1|x;\theta)$

在给定参数下，$h$函数判断同意数据为0的概率和为1的概率应该和是1

$P(y=0|x;\theta)+P(y=1|x;\theta)=1$

### 决策界限

根据上图所示，当$g$的参数$\ge0$时，$g$函数的值大于$0.5$，相应的当$g$的参数$\lt0$时，$g$函数的值小于$0.5$,而$g$函数的参数又是$\theta^TX$，所以我们可以得到结论当$\theta^TX\ge0$时，$h_{\theta}(x)\ge0.5$，当$\theta^TX<0$时，$h_{\theta}(x)>0.5$

